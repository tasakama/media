{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBdYFURJEeFRoLWSN0t5nd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tasakama/media/blob/main/media_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj0lkr0CZJst"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import sklearn.metrics.pairwise as F\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.functional import cosine_similarity\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Projector(nn.Module):\n",
        "  def __init__(self, in_dim, out_dim=2048):\n",
        "    super(Projector, self).__init__()\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(in_dim, in_dim, bias=False),\n",
        "        nn.BatchNorm1d(in_dim),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(in_dim, in_dim, bias=False),\n",
        "        nn.BatchNorm1d(in_dim),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(in_dim, out_dim, bias=False),\n",
        "        nn.BatchNorm1d(out_dim),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "\n",
        "class Predictor(nn.Module):\n",
        "  def __init__(self, in_dim=2048, pred_dim=512, out_dim=2048):\n",
        "    super(Predictor, self).__init__()\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(in_dim, pred_dim, bias=False),\n",
        "        nn.BatchNorm1d(pred_dim),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(pred_dim, out_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "      return self.layers(x)\n",
        "\n",
        "\n",
        "class SimSiam(nn.Module):\n",
        "  def __init__(self, backbone, projector, predictor):\n",
        "    super(SimSiam, self).__init__()\n",
        "\n",
        "    self.backbone = backbone\n",
        "    self.projector = projector\n",
        "    self.predictor = predictor\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    # x1,x2は変形後の画像を表す\n",
        "    z1 = self.projector(self.backbone(x1).flatten(start_dim=1))\n",
        "    z2 = self.projector(self.backbone(x2).flatten(start_dim=1))\n",
        "\n",
        "    p1 = self.predictor(z1)\n",
        "    p2 = self.predictor(z2)\n",
        "\n",
        "    # .detach()で勾配停止させる\n",
        "    return p1, p2, z1.detach(), z2.detach()\n",
        "\n",
        "\n",
        "class SimSiamDataset(Dataset):\n",
        "  def __init__(self, root, transform1, transform2, train=True):\n",
        "    self.dataset = datasets.CIFAR10(root=root, train=train, download=True)\n",
        "    self.transform1 = transform1\n",
        "    self.transform2 = transform2\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image, label = self.dataset[idx]\n",
        "    image1 = self.transform1(image)\n",
        "    image2 = self.transform2(image)\n",
        "    return image1, image2, label\n",
        "\n",
        "\n",
        "def negative_cosine(p, z):\n",
        "  return -cosine_similarity(p, z, dim=1).mean()\n",
        "\n",
        "\n",
        "def feature_for_knn(model, data_loader, culculate_type):\n",
        "  # simsiamモデルを評価用に設定\n",
        "  model.eval()\n",
        "  features = []\n",
        "  labels = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    if culculate_type == \"train\":\n",
        "      for x, _, y in data_loader:\n",
        "        x = x.to(device)\n",
        "        feature = model.backbone(x).flatten(start_dim=1)\n",
        "        features.append(feature.cpu().numpy())\n",
        "        labels.append(y.cpu().numpy())\n",
        "    elif culculate_type == \"val\":\n",
        "      for x, y in data_loader:\n",
        "        x = x.to(device)\n",
        "        feature = model.backbone(x).flatten(start_dim=1)\n",
        "        features.append(feature.cpu().numpy())\n",
        "        labels.append(y.cpu().numpy())\n",
        "\n",
        "  features = np.concatenate(features, axis=0)\n",
        "  labels = np.concatenate(labels, axis=0)\n",
        "\n",
        "  return features, labels\n",
        "\n",
        "\n",
        "def knn_cosine(train_features, train_labels, val_features, k):\n",
        "\n",
        "  # コサイン類似度の計算\n",
        "  cosine_sim = -F.cosine_similarity(val_features, train_features)\n",
        "\n",
        "  # v2のラベルを推定\n",
        "  val_label_pred = []\n",
        "\n",
        "  for i in range(val_features.shape[0]):\n",
        "      # 上位k個の類似度が高い(-1に近い)インデックスを取得\n",
        "      top_k_indices = np.argsort(cosine_sim[i])[:k]\n",
        "      # 上位k個のラベルを取得\n",
        "      top_k_labels = train_labels[top_k_indices]\n",
        "      # 最頻出ラベルを取得\n",
        "      most_common_label = Counter(top_k_labels).most_common(1)[0][0]\n",
        "      val_label_pred.append(most_common_label)\n",
        "\n",
        "  val_label_pred = np.array(val_label_pred)\n",
        "\n",
        "  return val_label_pred"
      ],
      "metadata": {
        "id": "DtjVJMQZZOXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUの利用\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# backboneとして最終全結合層だけ除いたResnet18を利用する\n",
        "backbone = nn.Sequential(*list(models.resnet18(weights=None).children())[:-1]).to(device)\n",
        "\n",
        "# SimSiamモデルの用意\n",
        "projector = Projector(in_dim=512).to(device)\n",
        "predictor = Predictor().to(device)\n",
        "model = SimSiam(backbone, projector, predictor).to(device)\n",
        "\n",
        "# データセット変形用\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32, scale=(0.2, 1.)),\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
        "    ], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = SimSiamDataset(\n",
        "    root='./data',\n",
        "    transform1=transform,\n",
        "    transform2=transform,\n",
        "    train=True\n",
        ")\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=2)\n",
        "\n",
        "val_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False, num_workers=2)\n",
        "\n",
        "# 最適化手法の設定\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.03, momentum=0.9, weight_decay=0.0005)"
      ],
      "metadata": {
        "id": "39N5K9_9ZQl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習ループ\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  for x1, x2, _ in train_loader:\n",
        "    x1, x2 = x1.to(device), x2.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    p1, p2, z1, z2 = model(x1, x2)\n",
        "    loss = negative_cosine(p1, z2)/2 + negative_cosine(p2, z1)/2\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')\n",
        "\n",
        "  if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "    train_features, train_labels = feature_for_knn(model, train_loader, \"train\")\n",
        "    val_features, val_labels = feature_for_knn(model, val_loader, \"val\")\n",
        "\n",
        "    # 予測ラベルの計算\n",
        "    predictions = knn_cosine(train_features, train_labels, val_features, k=200)\n",
        "\n",
        "    accuracy = accuracy_score(val_labels, predictions)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], k-NN Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "wMHD4TkgZVGC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}